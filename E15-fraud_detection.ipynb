{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 15\n",
    "\n",
    "# Fraud Detection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "- Fraud Detection Dataset from Microsoft Azure: [data](http://gallery.cortanaintelligence.com/Experiment/8e9fe4e03b8b4c65b9ca947c72b8e463)\n",
    "\n",
    "Fraud detection is one of the earliest industrial applications of data mining and machine learning. Fraud detection is typically handled as a binary classification problem, but the class population is unbalanced because instances of fraud are usually very rare compared to the overall volume of transactions. Moreover, when fraudulent transactions are discovered, the business typically takes measures to block the accounts from transacting to prevent further losses. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import cross_val_score, train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn import metrics\n",
    "from collections import Counter\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accountAge</th>\n",
       "      <th>digitalItemCount</th>\n",
       "      <th>sumPurchaseCount1Day</th>\n",
       "      <th>sumPurchaseAmount1Day</th>\n",
       "      <th>sumPurchaseAmount30Day</th>\n",
       "      <th>paymentBillingPostalCode - LogOddsForClass_0</th>\n",
       "      <th>accountPostalCode - LogOddsForClass_0</th>\n",
       "      <th>paymentBillingState - LogOddsForClass_0</th>\n",
       "      <th>accountState - LogOddsForClass_0</th>\n",
       "      <th>paymentInstrumentAgeInAccount</th>\n",
       "      <th>ipState - LogOddsForClass_0</th>\n",
       "      <th>transactionAmount</th>\n",
       "      <th>transactionAmountUSD</th>\n",
       "      <th>ipPostalCode - LogOddsForClass_0</th>\n",
       "      <th>localHour - LogOddsForClass_0</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>720.25</td>\n",
       "      <td>5.064533</td>\n",
       "      <td>0.421214</td>\n",
       "      <td>1.312186</td>\n",
       "      <td>0.566395</td>\n",
       "      <td>3279.574306</td>\n",
       "      <td>1.218157</td>\n",
       "      <td>599.00</td>\n",
       "      <td>626.164650</td>\n",
       "      <td>1.259543</td>\n",
       "      <td>4.745402</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>62</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1185.44</td>\n",
       "      <td>2530.37</td>\n",
       "      <td>0.538996</td>\n",
       "      <td>0.481838</td>\n",
       "      <td>4.401370</td>\n",
       "      <td>4.500157</td>\n",
       "      <td>61.970139</td>\n",
       "      <td>4.035601</td>\n",
       "      <td>1185.44</td>\n",
       "      <td>1185.440000</td>\n",
       "      <td>3.981118</td>\n",
       "      <td>4.921349</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>5.064533</td>\n",
       "      <td>5.096396</td>\n",
       "      <td>3.056357</td>\n",
       "      <td>3.155226</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.314186</td>\n",
       "      <td>32.09</td>\n",
       "      <td>32.090000</td>\n",
       "      <td>5.008490</td>\n",
       "      <td>4.742303</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>5.064533</td>\n",
       "      <td>5.096396</td>\n",
       "      <td>3.331154</td>\n",
       "      <td>3.331239</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.529398</td>\n",
       "      <td>133.28</td>\n",
       "      <td>132.729554</td>\n",
       "      <td>1.324925</td>\n",
       "      <td>4.745402</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>132.73</td>\n",
       "      <td>5.412885</td>\n",
       "      <td>0.342945</td>\n",
       "      <td>5.563677</td>\n",
       "      <td>4.086965</td>\n",
       "      <td>0.001389</td>\n",
       "      <td>3.529398</td>\n",
       "      <td>543.66</td>\n",
       "      <td>543.660000</td>\n",
       "      <td>2.693451</td>\n",
       "      <td>4.876771</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   accountAge  digitalItemCount  sumPurchaseCount1Day  sumPurchaseAmount1Day  \\\n",
       "0        2000                 0                     0                   0.00   \n",
       "1          62                 1                     1                1185.44   \n",
       "2        2000                 0                     0                   0.00   \n",
       "3           1                 1                     0                   0.00   \n",
       "4           1                 1                     0                   0.00   \n",
       "\n",
       "   sumPurchaseAmount30Day  paymentBillingPostalCode - LogOddsForClass_0  \\\n",
       "0                  720.25                                      5.064533   \n",
       "1                 2530.37                                      0.538996   \n",
       "2                    0.00                                      5.064533   \n",
       "3                    0.00                                      5.064533   \n",
       "4                  132.73                                      5.412885   \n",
       "\n",
       "   accountPostalCode - LogOddsForClass_0  \\\n",
       "0                               0.421214   \n",
       "1                               0.481838   \n",
       "2                               5.096396   \n",
       "3                               5.096396   \n",
       "4                               0.342945   \n",
       "\n",
       "   paymentBillingState - LogOddsForClass_0  accountState - LogOddsForClass_0  \\\n",
       "0                                 1.312186                          0.566395   \n",
       "1                                 4.401370                          4.500157   \n",
       "2                                 3.056357                          3.155226   \n",
       "3                                 3.331154                          3.331239   \n",
       "4                                 5.563677                          4.086965   \n",
       "\n",
       "   paymentInstrumentAgeInAccount  ipState - LogOddsForClass_0  \\\n",
       "0                    3279.574306                     1.218157   \n",
       "1                      61.970139                     4.035601   \n",
       "2                       0.000000                     3.314186   \n",
       "3                       0.000000                     3.529398   \n",
       "4                       0.001389                     3.529398   \n",
       "\n",
       "   transactionAmount  transactionAmountUSD  ipPostalCode - LogOddsForClass_0  \\\n",
       "0             599.00            626.164650                          1.259543   \n",
       "1            1185.44           1185.440000                          3.981118   \n",
       "2              32.09             32.090000                          5.008490   \n",
       "3             133.28            132.729554                          1.324925   \n",
       "4             543.66            543.660000                          2.693451   \n",
       "\n",
       "   localHour - LogOddsForClass_0  Label  \n",
       "0                       4.745402      0  \n",
       "1                       4.921349      0  \n",
       "2                       4.742303      0  \n",
       "3                       4.745402      0  \n",
       "4                       4.876771      0  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "url = 'https://raw.githubusercontent.com/albahnsen/PracticalMachineLearningClass/master/datasets/15_fraud_detection.csv.zip'\n",
    "df = pd.read_csv(url, index_col=0)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((138721, 16), 797, 0.0057453449730033666)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape, df.Label.sum(), df.Label.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "accountAge                                        int64\n",
       "digitalItemCount                                  int64\n",
       "sumPurchaseCount1Day                              int64\n",
       "sumPurchaseAmount1Day                           float64\n",
       "sumPurchaseAmount30Day                          float64\n",
       "paymentBillingPostalCode - LogOddsForClass_0    float64\n",
       "accountPostalCode - LogOddsForClass_0           float64\n",
       "paymentBillingState - LogOddsForClass_0         float64\n",
       "accountState - LogOddsForClass_0                float64\n",
       "paymentInstrumentAgeInAccount                   float64\n",
       "ipState - LogOddsForClass_0                     float64\n",
       "transactionAmount                               float64\n",
       "transactionAmountUSD                            float64\n",
       "ipPostalCode - LogOddsForClass_0                float64\n",
       "localHour - LogOddsForClass_0                   float64\n",
       "Label                                             int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 15.1\n",
    "\n",
    "Estimate a Logistic Regression, Decision Tree and Random Forest\n",
    "\n",
    "Evaluate using the following metrics:\n",
    "* Accuracy\n",
    "* F1-Score\n",
    "* F_Beta-Score (Beta=10)\n",
    "\n",
    "Comment about the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# specify seed for reproducable results\n",
    "seed = 42\n",
    "\n",
    "# define X and y\n",
    "X = df.drop(['Label'], axis=1).values\n",
    "y = df['Label'].values\n",
    "\n",
    "# standarize features\n",
    "scaler = StandardScaler()\n",
    "X = scaler.fit_transform(X.astype(np.float))\n",
    "\n",
    "# split dataframe into train and test set\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F-Beta Score</th>\n",
       "      <th>F1-Score</th>\n",
       "      <th>Model</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.988971</td>\n",
       "      <td>0.146696</td>\n",
       "      <td>0.135593</td>\n",
       "      <td>Decision Tree</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.994065</td>\n",
       "      <td>0.074089</td>\n",
       "      <td>0.127208</td>\n",
       "      <td>Random Forest</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.994113</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>Logistic Regression</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Accuracy  F-Beta Score  F1-Score                Model\n",
       "1  0.988971      0.146696  0.135593        Decision Tree\n",
       "2  0.994065      0.074089  0.127208        Random Forest\n",
       "0  0.994113      0.000000  0.000000  Logistic Regression"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# define models\n",
    "models = {'Logistic Regression':LogisticRegression(solver='liblinear', random_state=seed), \n",
    "         'Decision Tree':DecisionTreeClassifier(random_state=seed), \n",
    "         'Random Forest':RandomForestClassifier(n_estimators=50, n_jobs=-1, random_state=seed)}\n",
    "\n",
    "y_pred = pd.DataFrame(columns=models.keys())\n",
    "results = []\n",
    "\n",
    "# train, predict and evaluate each model\n",
    "for model in models.keys():\n",
    "    models[model].fit(X_train, y_train)\n",
    "    y_pred[model] = models[model].predict(X_test)\n",
    "    results.append({'Accuracy': metrics.accuracy_score(y_test, y_pred[model]),\n",
    "                    'F1-Score': metrics.f1_score(y_test, y_pred[model]),\n",
    "                    'Model': str(model),\n",
    "                    'F-Beta Score': metrics.fbeta_score(y_test, y_pred[model], beta=10)}) #f-beta > 1 favors recall (punishing FN)\n",
    "\n",
    "# store results on dataframe\n",
    "results = pd.DataFrame(results)\n",
    "results.sort_values('F-Beta Score', inplace=True, ascending=False)\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this specific scenario (fraud detection), it is more important to correctly label an instance as fraudulent, as opposed to labeling the non-fraudulent one. Based on this I'll use F-Beta Score as the main metric for evaluating the model's performance: \n",
    "\n",
    "- **Decision Tree:** is the one that's performing better, so far.\n",
    "- **Decision Tree** and **Random Forest** are capable of predicting actual fraud (TP), but they performance is quite limited.\n",
    "- **Logistic Regression:** is not capable of classifying true positive values (predicting actual fraud).\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 15.2\n",
    "\n",
    "Under-sample the negative class using random-under-sampling\n",
    "\n",
    "Which is parameter for target_percentage did you choose?\n",
    "How the results change?\n",
    "\n",
    "**Only apply under-sampling to the training set, evaluate using the whole test set**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def UnderSampling(X, y, target_percentage=0.5, seed=None):\n",
    "    # Assuming minority class is the positive\n",
    "    n_samples = y.shape[0]\n",
    "    n_samples_0 = (y == 0).sum()\n",
    "    n_samples_1 = (y == 1).sum()\n",
    "\n",
    "    n_samples_0_new =  n_samples_1 / target_percentage - n_samples_1\n",
    "    n_samples_0_new_per = n_samples_0_new / n_samples_0\n",
    "\n",
    "    filter_ = y == 0\n",
    "\n",
    "    np.random.seed(seed)\n",
    "    rand_1 = np.random.binomial(n=1, p=n_samples_0_new_per, size=n_samples)\n",
    "    \n",
    "    filter_ = filter_ & rand_1\n",
    "    filter_ = filter_ | (y == 1)\n",
    "    filter_ = filter_.astype(bool)\n",
    "    \n",
    "    return X[filter_], y[filter_]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F-Beta Score</th>\n",
       "      <th>F1-Score</th>\n",
       "      <th>Model</th>\n",
       "      <th>Target percentage</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.858471</td>\n",
       "      <td>0.523883</td>\n",
       "      <td>0.050918</td>\n",
       "      <td>Random Forest_UnderSampling</td>\n",
       "      <td>0.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.759401</td>\n",
       "      <td>0.522122</td>\n",
       "      <td>0.034519</td>\n",
       "      <td>Random Forest_UnderSampling</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.909100</td>\n",
       "      <td>0.492265</td>\n",
       "      <td>0.067997</td>\n",
       "      <td>Random Forest_UnderSampling</td>\n",
       "      <td>0.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.953961</td>\n",
       "      <td>0.455110</td>\n",
       "      <td>0.110492</td>\n",
       "      <td>Random Forest_UnderSampling</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.789894</td>\n",
       "      <td>0.454969</td>\n",
       "      <td>0.033171</td>\n",
       "      <td>Decision Tree_UnderSampling</td>\n",
       "      <td>0.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.629959</td>\n",
       "      <td>0.449326</td>\n",
       "      <td>0.022595</td>\n",
       "      <td>Decision Tree_UnderSampling</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.615542</td>\n",
       "      <td>0.425426</td>\n",
       "      <td>0.020928</td>\n",
       "      <td>Logistic Regression_UnderSampling</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.744768</td>\n",
       "      <td>0.422138</td>\n",
       "      <td>0.026933</td>\n",
       "      <td>Decision Tree_UnderSampling</td>\n",
       "      <td>0.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.846217</td>\n",
       "      <td>0.382563</td>\n",
       "      <td>0.035273</td>\n",
       "      <td>Decision Tree_UnderSampling</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.917462</td>\n",
       "      <td>0.351348</td>\n",
       "      <td>0.053458</td>\n",
       "      <td>Decision Tree_UnderSampling</td>\n",
       "      <td>0.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.983276</td>\n",
       "      <td>0.325768</td>\n",
       "      <td>0.188811</td>\n",
       "      <td>Random Forest_UnderSampling</td>\n",
       "      <td>0.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.845544</td>\n",
       "      <td>0.297781</td>\n",
       "      <td>0.027534</td>\n",
       "      <td>Logistic Regression_UnderSampling</td>\n",
       "      <td>0.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.915467</td>\n",
       "      <td>0.242484</td>\n",
       "      <td>0.036692</td>\n",
       "      <td>Logistic Regression_UnderSampling</td>\n",
       "      <td>0.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.964630</td>\n",
       "      <td>0.137031</td>\n",
       "      <td>0.045396</td>\n",
       "      <td>Logistic Regression_UnderSampling</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.988466</td>\n",
       "      <td>0.044876</td>\n",
       "      <td>0.043825</td>\n",
       "      <td>Logistic Regression_UnderSampling</td>\n",
       "      <td>0.1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Accuracy  F-Beta Score  F1-Score                              Model  \\\n",
       "11  0.858471      0.523883  0.050918        Random Forest_UnderSampling   \n",
       "14  0.759401      0.522122  0.034519        Random Forest_UnderSampling   \n",
       "8   0.909100      0.492265  0.067997        Random Forest_UnderSampling   \n",
       "5   0.953961      0.455110  0.110492        Random Forest_UnderSampling   \n",
       "7   0.789894      0.454969  0.033171        Decision Tree_UnderSampling   \n",
       "13  0.629959      0.449326  0.022595        Decision Tree_UnderSampling   \n",
       "12  0.615542      0.425426  0.020928  Logistic Regression_UnderSampling   \n",
       "10  0.744768      0.422138  0.026933        Decision Tree_UnderSampling   \n",
       "4   0.846217      0.382563  0.035273        Decision Tree_UnderSampling   \n",
       "1   0.917462      0.351348  0.053458        Decision Tree_UnderSampling   \n",
       "2   0.983276      0.325768  0.188811        Random Forest_UnderSampling   \n",
       "9   0.845544      0.297781  0.027534  Logistic Regression_UnderSampling   \n",
       "6   0.915467      0.242484  0.036692  Logistic Regression_UnderSampling   \n",
       "3   0.964630      0.137031  0.045396  Logistic Regression_UnderSampling   \n",
       "0   0.988466      0.044876  0.043825  Logistic Regression_UnderSampling   \n",
       "\n",
       "    Target percentage  \n",
       "11                0.4  \n",
       "14                0.5  \n",
       "8                 0.3  \n",
       "5                 0.2  \n",
       "7                 0.3  \n",
       "13                0.5  \n",
       "12                0.5  \n",
       "10                0.4  \n",
       "4                 0.2  \n",
       "1                 0.1  \n",
       "2                 0.1  \n",
       "9                 0.4  \n",
       "6                 0.3  \n",
       "3                 0.2  \n",
       "0                 0.1  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_undrsamp = pd.DataFrame(columns=models.keys())\n",
    "results_undrsamp = []\n",
    "\n",
    "for target_pct in np.arange(0.1,0.6,0.1):\n",
    "    for model in models.keys():\n",
    "        X_undrsamp, y_undrsamp = UnderSampling(X_train, y_train, target_percentage=target_pct, seed=seed)\n",
    "        models[model].fit(X_undrsamp, y_undrsamp)\n",
    "        y_pred_undrsamp[model] = models[model].predict(X_test)\n",
    "        results_undrsamp.append({'Accuracy': metrics.accuracy_score(y_test, y_pred_undrsamp[model]),\n",
    "                        'F1-Score': metrics.f1_score(y_test, y_pred_undrsamp[model]),\n",
    "                        'F-Beta Score': metrics.fbeta_score(y_test, y_pred_undrsamp[model], beta=10),\n",
    "                        'Target percentage': target_pct,\n",
    "                        'Model': str(model)+'_UnderSampling'})\n",
    "\n",
    "results_undrsamp = pd.DataFrame(results_undrsamp)\n",
    "results_undrsamp.sort_values('F-Beta Score', inplace=True, ascending=False)\n",
    "results_undrsamp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When applying **under-sampling**, the model that's performing better is Random Forest with 0.4 as parameter for target_percentage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resampled dataset shape Counter({0: 806, 1: 552})\n",
      "y.shape =  1358 y.mean() =  0.406480117820324\n"
     ]
    }
   ],
   "source": [
    "# resample training data\n",
    "X_res, y_res = UnderSampling(X_train, y_train, target_percentage=0.4, seed=seed)\n",
    "\n",
    "print('Resampled dataset shape %s' % Counter(y_res))\n",
    "print('y.shape = ',y_res.shape[0], 'y.mean() = ', y_res.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F-Beta Score</th>\n",
       "      <th>F1-Score</th>\n",
       "      <th>Model</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.858471</td>\n",
       "      <td>0.523883</td>\n",
       "      <td>0.050918</td>\n",
       "      <td>Random Forest_UnderSampling</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.744768</td>\n",
       "      <td>0.422138</td>\n",
       "      <td>0.026933</td>\n",
       "      <td>Decision Tree_UnderSampling</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.845544</td>\n",
       "      <td>0.297781</td>\n",
       "      <td>0.027534</td>\n",
       "      <td>Logistic Regression_UnderSampling</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Accuracy  F-Beta Score  F1-Score                              Model\n",
       "11  0.858471      0.523883  0.050918        Random Forest_UnderSampling\n",
       "10  0.744768      0.422138  0.026933        Decision Tree_UnderSampling\n",
       "9   0.845544      0.297781  0.027534  Logistic Regression_UnderSampling"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_undrsamp = results_undrsamp[results_undrsamp['Target percentage'] == 0.4].drop('Target percentage', axis=1)\n",
    "results_undrsamp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 15.3\n",
    "\n",
    "Same analysis using random-over-sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "def OverSampling(X, y, target_percentage=0.5, seed=None):\n",
    "    # Assuming minority class is the positive\n",
    "    n_samples = y.shape[0]\n",
    "    n_samples_0 = (y == 0).sum()\n",
    "    n_samples_1 = (y == 1).sum()\n",
    "\n",
    "    n_samples_1_new =  -target_percentage * n_samples_0 / (target_percentage- 1)\n",
    "\n",
    "    np.random.seed(seed)\n",
    "    filter_ = np.random.choice(X[y == 1].shape[0], int(n_samples_1_new))\n",
    "    # filter_ is within the positives, change to be of all\n",
    "    filter_ = np.nonzero(y == 1)[0][filter_]\n",
    "    \n",
    "    filter_ = np.concatenate((filter_, np.nonzero(y == 0)[0]), axis=0)\n",
    "    \n",
    "    return X[filter_], y[filter_]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F-Beta Score</th>\n",
       "      <th>F1-Score</th>\n",
       "      <th>Model</th>\n",
       "      <th>Target percentage</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.659178</td>\n",
       "      <td>0.427271</td>\n",
       "      <td>0.022602</td>\n",
       "      <td>Logistic Regression_OverSampling</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.877646</td>\n",
       "      <td>0.280641</td>\n",
       "      <td>0.031202</td>\n",
       "      <td>Logistic Regression_OverSampling</td>\n",
       "      <td>0.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.946680</td>\n",
       "      <td>0.190035</td>\n",
       "      <td>0.043122</td>\n",
       "      <td>Logistic Regression_OverSampling</td>\n",
       "      <td>0.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.989908</td>\n",
       "      <td>0.138787</td>\n",
       "      <td>0.139344</td>\n",
       "      <td>Decision Tree_OverSampling</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.988683</td>\n",
       "      <td>0.130375</td>\n",
       "      <td>0.119626</td>\n",
       "      <td>Decision Tree_OverSampling</td>\n",
       "      <td>0.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.990076</td>\n",
       "      <td>0.122533</td>\n",
       "      <td>0.126850</td>\n",
       "      <td>Decision Tree_OverSampling</td>\n",
       "      <td>0.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.989668</td>\n",
       "      <td>0.122449</td>\n",
       "      <td>0.122449</td>\n",
       "      <td>Decision Tree_OverSampling</td>\n",
       "      <td>0.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.989716</td>\n",
       "      <td>0.118386</td>\n",
       "      <td>0.119342</td>\n",
       "      <td>Decision Tree_OverSampling</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.993704</td>\n",
       "      <td>0.115086</td>\n",
       "      <td>0.176101</td>\n",
       "      <td>Random Forest_OverSampling</td>\n",
       "      <td>0.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.977846</td>\n",
       "      <td>0.104087</td>\n",
       "      <td>0.053388</td>\n",
       "      <td>Logistic Regression_OverSampling</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.993632</td>\n",
       "      <td>0.102768</td>\n",
       "      <td>0.158730</td>\n",
       "      <td>Random Forest_OverSampling</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.993753</td>\n",
       "      <td>0.098685</td>\n",
       "      <td>0.155844</td>\n",
       "      <td>Random Forest_OverSampling</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.993632</td>\n",
       "      <td>0.094562</td>\n",
       "      <td>0.147910</td>\n",
       "      <td>Random Forest_OverSampling</td>\n",
       "      <td>0.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.993753</td>\n",
       "      <td>0.090476</td>\n",
       "      <td>0.144737</td>\n",
       "      <td>Random Forest_OverSampling</td>\n",
       "      <td>0.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.991446</td>\n",
       "      <td>0.028711</td>\n",
       "      <td>0.037838</td>\n",
       "      <td>Logistic Regression_OverSampling</td>\n",
       "      <td>0.1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Accuracy  F-Beta Score  F1-Score                             Model  \\\n",
       "12  0.659178      0.427271  0.022602  Logistic Regression_OverSampling   \n",
       "9   0.877646      0.280641  0.031202  Logistic Regression_OverSampling   \n",
       "6   0.946680      0.190035  0.043122  Logistic Regression_OverSampling   \n",
       "4   0.989908      0.138787  0.139344        Decision Tree_OverSampling   \n",
       "1   0.988683      0.130375  0.119626        Decision Tree_OverSampling   \n",
       "7   0.990076      0.122533  0.126850        Decision Tree_OverSampling   \n",
       "10  0.989668      0.122449  0.122449        Decision Tree_OverSampling   \n",
       "13  0.989716      0.118386  0.119342        Decision Tree_OverSampling   \n",
       "8   0.993704      0.115086  0.176101        Random Forest_OverSampling   \n",
       "3   0.977846      0.104087  0.053388  Logistic Regression_OverSampling   \n",
       "5   0.993632      0.102768  0.158730        Random Forest_OverSampling   \n",
       "14  0.993753      0.098685  0.155844        Random Forest_OverSampling   \n",
       "2   0.993632      0.094562  0.147910        Random Forest_OverSampling   \n",
       "11  0.993753      0.090476  0.144737        Random Forest_OverSampling   \n",
       "0   0.991446      0.028711  0.037838  Logistic Regression_OverSampling   \n",
       "\n",
       "    Target percentage  \n",
       "12                0.5  \n",
       "9                 0.4  \n",
       "6                 0.3  \n",
       "4                 0.2  \n",
       "1                 0.1  \n",
       "7                 0.3  \n",
       "10                0.4  \n",
       "13                0.5  \n",
       "8                 0.3  \n",
       "3                 0.2  \n",
       "5                 0.2  \n",
       "14                0.5  \n",
       "2                 0.1  \n",
       "11                0.4  \n",
       "0                 0.1  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_ovrsamp = pd.DataFrame(columns=models.keys())\n",
    "results_ovrsamp = []\n",
    "\n",
    "for target_pct in np.arange(0.1,0.6,0.1):\n",
    "    for model in models.keys():\n",
    "        X_ovrsamp, y_ovrsamp = OverSampling(X_train, y_train, target_percentage=target_pct, seed=seed)\n",
    "        models[model].fit(X_ovrsamp, y_ovrsamp)\n",
    "        y_pred_ovrsamp[model] = models[model].predict(X_test)\n",
    "        results_ovrsamp.append({'Accuracy': metrics.accuracy_score(y_test, y_pred_ovrsamp[model]),\n",
    "                        'F1-Score': metrics.f1_score(y_test, y_pred_ovrsamp[model]),\n",
    "                        'F-Beta Score': metrics.fbeta_score(y_test, y_pred_ovrsamp[model], beta=10),\n",
    "                        'Target percentage': target_pct,\n",
    "                        'Model': str(model)+'_OverSampling'})\n",
    "\n",
    "results_ovrsamp = pd.DataFrame(results_ovrsamp)\n",
    "results_ovrsamp.sort_values('F-Beta Score', inplace=True, ascending=False)\n",
    "results_ovrsamp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When applying **random-over-sampling**, the model that's performing better is Logistic Regression with 0.5 as parameter for target_percentage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resampled dataset shape Counter({1: 96552, 0: 96552})\n",
      "y.shape =  193104 y.mean() =  0.5\n"
     ]
    }
   ],
   "source": [
    "# resample training data\n",
    "X_res, y_res = OverSampling(X_train, y_train, target_percentage=0.5, seed=seed)\n",
    "\n",
    "print('Resampled dataset shape %s' % Counter(y_res))\n",
    "print('y.shape = ',y_res.shape[0], 'y.mean() = ', y_res.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F-Beta Score</th>\n",
       "      <th>F1-Score</th>\n",
       "      <th>Model</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.659178</td>\n",
       "      <td>0.427271</td>\n",
       "      <td>0.022602</td>\n",
       "      <td>Logistic Regression_OverSampling</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.989716</td>\n",
       "      <td>0.118386</td>\n",
       "      <td>0.119342</td>\n",
       "      <td>Decision Tree_OverSampling</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.993753</td>\n",
       "      <td>0.098685</td>\n",
       "      <td>0.155844</td>\n",
       "      <td>Random Forest_OverSampling</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Accuracy  F-Beta Score  F1-Score                             Model\n",
       "12  0.659178      0.427271  0.022602  Logistic Regression_OverSampling\n",
       "13  0.989716      0.118386  0.119342        Decision Tree_OverSampling\n",
       "14  0.993753      0.098685  0.155844        Random Forest_OverSampling"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_ovrsamp = results_ovrsamp[results_ovrsamp['Target percentage'] == 0.5].drop('Target percentage', axis=1)\n",
    "results_ovrsamp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 15.4 (3 points)\n",
    "\n",
    "Evaluate the results using SMOTE\n",
    "\n",
    "Which parameters did you choose?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def SMOTE(X, y, target_percentage=0.5, k=5, seed=None):\n",
    "    # Calculate the NearestNeighbors\n",
    "    from sklearn.neighbors import NearestNeighbors\n",
    "    nearest_neighbour_ = NearestNeighbors(n_neighbors=k + 1)\n",
    "    nearest_neighbour_.fit(X[y==1])\n",
    "    nns = nearest_neighbour_.kneighbors(X[y==1], \n",
    "                                    return_distance=False)[:, 1:]\n",
    "    # Assuming minority class is the positive\n",
    "    n_samples = y.shape[0]\n",
    "    n_samples_0 = (y == 0).sum()\n",
    "    n_samples_1 = (y == 1).sum()\n",
    "    \n",
    "    # New samples\n",
    "    n_samples_1_new =  int(-target_percentage * n_samples_0 / (target_percentage- 1) - n_samples_1)\n",
    "    \n",
    "    # A matrix to store the synthetic samples\n",
    "    new = np.zeros((n_samples_1_new, X.shape[1]))\n",
    "    \n",
    "    # Create seeds\n",
    "    np.random.seed(seed)\n",
    "    seeds = np.random.randint(1, 1000000, 3)\n",
    "    \n",
    "    # Select examples to use as base\n",
    "    np.random.seed(seeds[0])\n",
    "    sel_ = np.random.choice(y[y==1].shape[0], n_samples_1_new)\n",
    "    \n",
    "    # Define random seeds (2 per example)\n",
    "    np.random.seed(seeds[1])\n",
    "    nn__=[]\n",
    "    # Select one random neighbor for each example to use as base\n",
    "    for i, sel in enumerate(sel_):\n",
    "        nn__.append(np.random.choice(nns[sel]))\n",
    "    \n",
    "    np.random.seed(seeds[2])\n",
    "    steps = np.random.uniform(size=n_samples_1_new)  \n",
    "\n",
    "    # For each selected examples create one synthetic case\n",
    "    for i, sel in enumerate(sel_):\n",
    "        # Select neighbor\n",
    "        nn_ = nn__[i]\n",
    "        step = steps[i]\n",
    "        # Create new sample\n",
    "        new[i, :] = X[y==1][sel] - step * (X[y==1][sel] - X[y==1][nn_])\n",
    "    \n",
    "    X = np.vstack((X, new))\n",
    "    y = np.append(y, np.ones(n_samples_1_new))\n",
    "    \n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F-Beta Score</th>\n",
       "      <th>F1-Score</th>\n",
       "      <th>K</th>\n",
       "      <th>Model</th>\n",
       "      <th>Target percentage</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.619122</td>\n",
       "      <td>0.434419</td>\n",
       "      <td>0.021483</td>\n",
       "      <td>5</td>\n",
       "      <td>Logistic Regression_SMOTE</td>\n",
       "      <td>0.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.602638</td>\n",
       "      <td>0.427175</td>\n",
       "      <td>0.020610</td>\n",
       "      <td>15</td>\n",
       "      <td>Logistic Regression_SMOTE</td>\n",
       "      <td>0.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.981089</td>\n",
       "      <td>0.172835</td>\n",
       "      <td>0.098511</td>\n",
       "      <td>15</td>\n",
       "      <td>Decision Tree_SMOTE</td>\n",
       "      <td>0.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.980104</td>\n",
       "      <td>0.156552</td>\n",
       "      <td>0.086093</td>\n",
       "      <td>5</td>\n",
       "      <td>Decision Tree_SMOTE</td>\n",
       "      <td>0.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.990389</td>\n",
       "      <td>0.155190</td>\n",
       "      <td>0.159664</td>\n",
       "      <td>15</td>\n",
       "      <td>Random Forest_SMOTE</td>\n",
       "      <td>0.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.991998</td>\n",
       "      <td>0.143361</td>\n",
       "      <td>0.173697</td>\n",
       "      <td>15</td>\n",
       "      <td>Random Forest_SMOTE</td>\n",
       "      <td>0.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.978927</td>\n",
       "      <td>0.140267</td>\n",
       "      <td>0.073918</td>\n",
       "      <td>15</td>\n",
       "      <td>Decision Tree_SMOTE</td>\n",
       "      <td>0.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.965279</td>\n",
       "      <td>0.137175</td>\n",
       "      <td>0.046205</td>\n",
       "      <td>5</td>\n",
       "      <td>Logistic Regression_SMOTE</td>\n",
       "      <td>0.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.964702</td>\n",
       "      <td>0.137047</td>\n",
       "      <td>0.045484</td>\n",
       "      <td>15</td>\n",
       "      <td>Logistic Regression_SMOTE</td>\n",
       "      <td>0.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.992047</td>\n",
       "      <td>0.135202</td>\n",
       "      <td>0.166247</td>\n",
       "      <td>5</td>\n",
       "      <td>Random Forest_SMOTE</td>\n",
       "      <td>0.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.992647</td>\n",
       "      <td>0.131249</td>\n",
       "      <td>0.172973</td>\n",
       "      <td>5</td>\n",
       "      <td>Random Forest_SMOTE</td>\n",
       "      <td>0.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.982219</td>\n",
       "      <td>0.128976</td>\n",
       "      <td>0.079602</td>\n",
       "      <td>5</td>\n",
       "      <td>Decision Tree_SMOTE</td>\n",
       "      <td>0.25</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Accuracy  F-Beta Score  F1-Score   K                      Model  \\\n",
       "6   0.619122      0.434419  0.021483   5  Logistic Regression_SMOTE   \n",
       "9   0.602638      0.427175  0.020610  15  Logistic Regression_SMOTE   \n",
       "4   0.981089      0.172835  0.098511  15        Decision Tree_SMOTE   \n",
       "7   0.980104      0.156552  0.086093   5        Decision Tree_SMOTE   \n",
       "11  0.990389      0.155190  0.159664  15        Random Forest_SMOTE   \n",
       "5   0.991998      0.143361  0.173697  15        Random Forest_SMOTE   \n",
       "10  0.978927      0.140267  0.073918  15        Decision Tree_SMOTE   \n",
       "0   0.965279      0.137175  0.046205   5  Logistic Regression_SMOTE   \n",
       "3   0.964702      0.137047  0.045484  15  Logistic Regression_SMOTE   \n",
       "8   0.992047      0.135202  0.166247   5        Random Forest_SMOTE   \n",
       "2   0.992647      0.131249  0.172973   5        Random Forest_SMOTE   \n",
       "1   0.982219      0.128976  0.079602   5        Decision Tree_SMOTE   \n",
       "\n",
       "    Target percentage  \n",
       "6                0.50  \n",
       "9                0.50  \n",
       "4                0.25  \n",
       "7                0.50  \n",
       "11               0.50  \n",
       "5                0.25  \n",
       "10               0.50  \n",
       "0                0.25  \n",
       "3                0.25  \n",
       "8                0.50  \n",
       "2                0.25  \n",
       "1                0.25  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_smote = pd.DataFrame(columns=models.keys())\n",
    "results_smote = []\n",
    "\n",
    "for target_pct in [0.25, 0.5]:\n",
    "    for k in [5, 15]:\n",
    "        for model in models.keys():\n",
    "            X_smote, y_smote = SMOTE(X_train, y_train, target_percentage=target_pct, k=k, seed=seed)\n",
    "            models[model].fit(X_smote, y_smote)\n",
    "            y_pred_smote[model] = models[model].predict(X_test)\n",
    "            results_smote.append({'Accuracy': metrics.accuracy_score(y_test, y_pred_smote[model]),\n",
    "                                'F1-Score': metrics.f1_score(y_test, y_pred_smote[model]),\n",
    "                                'F-Beta Score': metrics.fbeta_score(y_test, y_pred_smote[model], beta=10),\n",
    "                                'Target percentage': target_pct,\n",
    "                                'Model': str(model)+'_SMOTE',\n",
    "                                'K': k})\n",
    "\n",
    "results_smote = pd.DataFrame(results_smote)\n",
    "results_smote.sort_values('F-Beta Score', inplace=True, ascending=False)\n",
    "results_smote"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When using **SMOTE**, the model that's performing better is Logistic Regression with 0.5 as parameter for target_percentage and 5 for K."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resampled dataset shape Counter({0.0: 96552, 1.0: 96552})\n",
      "y.shape =  193104 y.mean() =  0.5\n"
     ]
    }
   ],
   "source": [
    "# Resample training data\n",
    "X_res, y_res = SMOTE(X_train, y_train, target_percentage=0.50, k=5, seed=seed)\n",
    "\n",
    "print('Resampled dataset shape %s' % Counter(y_res))\n",
    "print('y.shape = ',y_res.shape[0], 'y.mean() = ', y_res.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F-Beta Score</th>\n",
       "      <th>F1-Score</th>\n",
       "      <th>Model</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.619122</td>\n",
       "      <td>0.434419</td>\n",
       "      <td>0.021483</td>\n",
       "      <td>Logistic Regression_SMOTE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.980104</td>\n",
       "      <td>0.156552</td>\n",
       "      <td>0.086093</td>\n",
       "      <td>Decision Tree_SMOTE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.992047</td>\n",
       "      <td>0.135202</td>\n",
       "      <td>0.166247</td>\n",
       "      <td>Random Forest_SMOTE</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Accuracy  F-Beta Score  F1-Score                      Model\n",
       "6  0.619122      0.434419  0.021483  Logistic Regression_SMOTE\n",
       "7  0.980104      0.156552  0.086093        Decision Tree_SMOTE\n",
       "8  0.992047      0.135202  0.166247        Random Forest_SMOTE"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_smote = results_smote[(results_smote['Target percentage'] == 0.5) & (results_smote['K'] == 5)].drop(['Target percentage', 'K'], axis=1)\n",
    "results_smote"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 15.5 (3 points)\n",
    "\n",
    "Evaluate the results using Adaptive Synthetic Sampling Approach for Imbalanced\n",
    "Learning (ADASYN)\n",
    "\n",
    "http://www.ele.uri.edu/faculty/he/PDFfiles/adasyn.pdf\n",
    "https://imbalanced-learn.readthedocs.io/en/stable/generated/imblearn.over_sampling.ADASYN.html#rf9172e970ca5-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resampled dataset shape Counter({1: 96604, 0: 96552})\n",
      "y.shape =  193156 y.mean() =  0.5001346062250202\n"
     ]
    }
   ],
   "source": [
    "from imblearn.over_sampling import ADASYN\n",
    "\n",
    "# Resample training data\n",
    "ada = ADASYN(sampling_strategy='minority', random_state=seed, n_neighbors=5, n_jobs=-1)\n",
    "X_res, y_res = ada.fit_resample(X_train, y_train)\n",
    "\n",
    "print('Resampled dataset shape %s' % Counter(y_res))\n",
    "print('y.shape = ',y_res.shape[0], 'y.mean() = ', y_res.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F-Beta Score</th>\n",
       "      <th>F1-Score</th>\n",
       "      <th>Model</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.589903</td>\n",
       "      <td>0.426549</td>\n",
       "      <td>0.020208</td>\n",
       "      <td>Logistic Regression_ADASYN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.980369</td>\n",
       "      <td>0.180630</td>\n",
       "      <td>0.099228</td>\n",
       "      <td>Decision Tree_ADASYN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.992215</td>\n",
       "      <td>0.131153</td>\n",
       "      <td>0.164948</td>\n",
       "      <td>Random Forest_ADASYN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Accuracy  F-Beta Score  F1-Score                       Model\n",
       "0  0.589903      0.426549  0.020208  Logistic Regression_ADASYN\n",
       "1  0.980369      0.180630  0.099228        Decision Tree_ADASYN\n",
       "2  0.992215      0.131153  0.164948        Random Forest_ADASYN"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_ada = pd.DataFrame(columns=models.keys())\n",
    "results_ada = []\n",
    "\n",
    "# train, predict and evaluate each model\n",
    "for model in models.keys():\n",
    "    models[model].fit(X_res, y_res)\n",
    "    y_pred_ada[model] = models[model].predict(X_test)\n",
    "    results_ada.append({'Accuracy': metrics.accuracy_score(y_test, y_pred_ada[model]),\n",
    "                        'F1-Score': metrics.f1_score(y_test, y_pred_ada[model]),\n",
    "                        'Model': str(model)+'_ADASYN',\n",
    "                        'F-Beta Score': metrics.fbeta_score(y_test, y_pred_ada[model], beta=10)}) #f-beta > 1 favors recall (punishing FN)\n",
    "\n",
    "# store results on dataframe\n",
    "results_ada = pd.DataFrame(results_ada)\n",
    "results_ada"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this specific scenario (fraud detection), it is more important to correctly label an instance as fraudulent, as opposed to labeling the non-fraudulent one. Based on this I'll use F-Beta Score as the main metric for evaluating the model's performance: \n",
    "\n",
    "- **Logistic Regression:** is the one that's performing better.\n",
    "- **Decision Tree** and **Random Forest** are capable of predicting actual fraud (TP), and they accuracy is quite good. Nevertheless, they struggle to predict actual fraud."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 15.6 (3 points)\n",
    "\n",
    "Compare and comment about the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F-Beta Score</th>\n",
       "      <th>F1-Score</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Model</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Random Forest_UnderSampling</th>\n",
       "      <td>0.858471</td>\n",
       "      <td>0.523883</td>\n",
       "      <td>0.050918</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Logistic Regression_SMOTE</th>\n",
       "      <td>0.619122</td>\n",
       "      <td>0.434419</td>\n",
       "      <td>0.021483</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Logistic Regression_OverSampling</th>\n",
       "      <td>0.659178</td>\n",
       "      <td>0.427271</td>\n",
       "      <td>0.022602</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Logistic Regression_ADASYN</th>\n",
       "      <td>0.589903</td>\n",
       "      <td>0.426549</td>\n",
       "      <td>0.020208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Decision Tree_UnderSampling</th>\n",
       "      <td>0.744768</td>\n",
       "      <td>0.422138</td>\n",
       "      <td>0.026933</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Logistic Regression_UnderSampling</th>\n",
       "      <td>0.845544</td>\n",
       "      <td>0.297781</td>\n",
       "      <td>0.027534</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Decision Tree_ADASYN</th>\n",
       "      <td>0.980369</td>\n",
       "      <td>0.180630</td>\n",
       "      <td>0.099228</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Decision Tree_SMOTE</th>\n",
       "      <td>0.980104</td>\n",
       "      <td>0.156552</td>\n",
       "      <td>0.086093</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Decision Tree</th>\n",
       "      <td>0.988971</td>\n",
       "      <td>0.146696</td>\n",
       "      <td>0.135593</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Random Forest_SMOTE</th>\n",
       "      <td>0.992047</td>\n",
       "      <td>0.135202</td>\n",
       "      <td>0.166247</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Random Forest_ADASYN</th>\n",
       "      <td>0.992215</td>\n",
       "      <td>0.131153</td>\n",
       "      <td>0.164948</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Decision Tree_OverSampling</th>\n",
       "      <td>0.989716</td>\n",
       "      <td>0.118386</td>\n",
       "      <td>0.119342</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Random Forest_OverSampling</th>\n",
       "      <td>0.993753</td>\n",
       "      <td>0.098685</td>\n",
       "      <td>0.155844</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Random Forest</th>\n",
       "      <td>0.994065</td>\n",
       "      <td>0.074089</td>\n",
       "      <td>0.127208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Logistic Regression</th>\n",
       "      <td>0.994113</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   Accuracy  F-Beta Score  F1-Score\n",
       "Model                                                              \n",
       "Random Forest_UnderSampling        0.858471      0.523883  0.050918\n",
       "Logistic Regression_SMOTE          0.619122      0.434419  0.021483\n",
       "Logistic Regression_OverSampling   0.659178      0.427271  0.022602\n",
       "Logistic Regression_ADASYN         0.589903      0.426549  0.020208\n",
       "Decision Tree_UnderSampling        0.744768      0.422138  0.026933\n",
       "Logistic Regression_UnderSampling  0.845544      0.297781  0.027534\n",
       "Decision Tree_ADASYN               0.980369      0.180630  0.099228\n",
       "Decision Tree_SMOTE                0.980104      0.156552  0.086093\n",
       "Decision Tree                      0.988971      0.146696  0.135593\n",
       "Random Forest_SMOTE                0.992047      0.135202  0.166247\n",
       "Random Forest_ADASYN               0.992215      0.131153  0.164948\n",
       "Decision Tree_OverSampling         0.989716      0.118386  0.119342\n",
       "Random Forest_OverSampling         0.993753      0.098685  0.155844\n",
       "Random Forest                      0.994065      0.074089  0.127208\n",
       "Logistic Regression                0.994113      0.000000  0.000000"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_final = results.merge(results_undrsamp, how='outer').merge(results_ovrsamp, how='outer').merge(results_smote, how='outer').merge(results_ada, how='outer').set_index('Model')\n",
    "df_final.sort_values('F-Beta Score', inplace=True, ascending=False)\n",
    "df_final"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After training **three different machine learning models** (Logistic Regression, Decision Tree and Random Forest) and implemeting **two resampling techniques**: Under-sampling the majority class and Over-sampling the minority class, the **best performance** was achieved by a Random Forest using UnderSampling technique, with 0.4 as parameter for target_percentage. **F-Beta Score** was used as the main metric for evaluating the model's performance, because in this specific scenario (fraud detection), it is more important to correctly label an instance as fraudulent, as opposed to labeling the non-fraudulent one."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
